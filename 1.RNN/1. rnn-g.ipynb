{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ok', 'he', 'hello', 'i', 'will', 'eat', 'can', 'say', 'sing', 'she', 'egg', 'go', 'you']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "sentence_list = ['i say hello', 'you eat egg', 'he can sing', 'she will go', 'i say ok']\n",
    "\n",
    "words = ' '.join(sentence_list).split(' ')\n",
    "all_words = list(set(words))\n",
    "print(all_words)\n",
    "all_words_len = len(all_words)\n",
    "print(all_words_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ok', 1: 'he', 2: 'hello', 3: 'i', 4: 'will', 5: 'eat', 6: 'can', 7: 'say', 8: 'sing', 9: 'she', 10: 'egg', 11: 'go', 12: 'you'}\n",
      "{'ok': 0, 'he': 1, 'hello': 2, 'i': 3, 'will': 4, 'eat': 5, 'can': 6, 'say': 7, 'sing': 8, 'she': 9, 'egg': 10, 'go': 11, 'you': 12}\n"
     ]
    }
   ],
   "source": [
    "# 构建i2v，v2i\n",
    "index2word = {k: v for k, v in enumerate(all_words)}\n",
    "word2index = {v: k for k, v in enumerate(all_words)}\n",
    "print(index2word)\n",
    "print(word2index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## 构建x(输入值)和y(预测值)，并把x(输入值)和y(预测值)转为one-hot编码\n",
    "def make_data(sentence_list):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    for sentence in sentence_list:\n",
    "        # 将句子切分为单词,然后再将前两个单词作为x(输入值),最后一个单词作为y(预测值)\n",
    "        word = sentence.split(' ')\n",
    "        input = [word2index[n] for n in word[:-1]]\n",
    "        output = word2index[word[-1]]\n",
    "        # np.eye(all_words_len)[input]可以理解为,将每个单词的编号转为 one-hot编码\n",
    "        # 输入值转为one-hot编码,输出值不用转,因为相当于13分类问题(一共有13种不同的单词)\n",
    "        input_batch.append(np.eye(all_words_len)[input])\n",
    "        output_batch.append(output)\n",
    "    print(input_batch)\n",
    "    print(output_batch)\n",
    "    return torch.Tensor(input_batch), torch.LongTensor(output_batch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "[2, 10, 8, 11, 0]\n",
      "-------\n",
      "tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]]) tensor([ 2, 10,  8, 11,  0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\pycharmshiyong\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch = make_data(sentence_list)\n",
    "print('-------')\n",
    "print(input_batch, output_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "## 构建dataset和dataloader\n",
    "dataset = Data.TensorDataset(input_batch, output_batch)\n",
    "dataloader = Data.DataLoader(dataset=dataset,\n",
    "                             batch_size=2,\n",
    "                             drop_last=True,\n",
    "                             shuffle=False)\n",
    "#shuffle是否打乱顺序，默认为False表示不打乱顺序\n",
    "# drop_last表示是否舍弃最后一个，\n",
    "#举例：本次总的数据是五个，每次运送两个数据,最后一句话,也就是'i say ok'不参加训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]]) torch.Size([2, 2, 13])\n",
      "tensor([ 2, 10]) torch.Size([2])\n",
      "----\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]]) torch.Size([2, 2, 13])\n",
      "tensor([ 8, 11]) torch.Size([2])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataloader:\n",
    "    print(x, x.shape)\n",
    "    # [2, 2, 13]\n",
    "    # 第一个2代表2个数据,也就是batch_size,\n",
    "    # 第二个2表示x(输入值)中单词的个数,本次是由前两个单词,来预测第三个单词\n",
    "    # 13 表示每个单词被编码为13维\n",
    "    print(y, y.shape)\n",
    "    print('----')\n",
    "    # 可以发现是两个一组进行输出,因为batch_size=2\n",
    "    ### 此时数据处理部分内容就已经完成,接下来构建RNN网络,将数据用dataloader送入到网络中"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./out.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "####构建RNN网络\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNN, self).__init__()\n",
    "        #all_words_len=13,也就是sentence_list中,总共有13种不同的单词,\n",
    "        # 也就预测最后一个单词,总共有13中不同的结果,也就是13分类问题\n",
    "        self.rnn = nn.RNN(input_size=all_words_len, hidden_size=6)\n",
    "        self.fc = nn.Linear(in_features=6, out_features=all_words_len)\n",
    "\n",
    "    #图片中使out,ht=forward(x,h0)\n",
    "    # 也就是 out,hidden = self.rnn(x,hidden)\n",
    "    # 这里采用input代表x，h_i代表h0(hidden)\n",
    "    # 就会变成out,ht=self.rnn(input,h_0) # rnn中数据放在第一个位置\n",
    "    def forward(self, input, h_0i):\n",
    "        input = input.transpose(0, 1)\n",
    "        # input是dataloader中的x数据,x数据的格式是\n",
    "        # RNN的前向传播,需要传入两个参数\n",
    "        out, h_0i = self.rnn(input, h_0i)\n",
    "        out = out[-1]\n",
    "        model = self.fc(out)\n",
    "        return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./rnn.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#实例化对象\n",
    "model = MyRNN()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyRNN(\n",
      "  (rnn): RNN(13, 6)\n",
      "  (fc): Linear(in_features=6, out_features=13, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "## 定义损失函数和优化器## 固定步骤\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1244, -0.1414, -0.1988, -1.5842, -1.6437, -2.9828],\n",
      "         [-1.3623,  1.9778,  0.5775,  0.8948,  0.4620,  0.3091]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.8851,  2.0004,  2.0992,  1.6781, -0.3298,  1.6590],\n",
      "         [-1.0266, -0.8749, -0.4643,  1.1039,  0.2930,  0.8305]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.7311,  0.8735, -0.6060, -0.2150, -1.6210, -0.5501],\n",
      "         [ 1.1710,  0.9384,  1.8335,  0.7064,  1.0579,  0.7806]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.6574,  1.6693, -0.9780,  1.2261,  0.5174, -0.0141],\n",
      "         [-0.4231,  0.5941, -0.3629,  0.5353, -0.6747,  2.7047]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.1894,  0.2971,  0.9485, -1.6390,  0.0634, -0.5142],\n",
      "         [ 1.1432, -0.3977,  0.0327, -0.4695, -0.5886,  0.6575]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.9998, -0.4463, -0.1910,  0.1717,  0.2496,  0.5408],\n",
      "         [ 1.1981, -1.3899,  0.3856, -1.1947,  0.6418,  1.3522]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.3168, -0.1536, -1.6091,  0.1001, -1.3394, -0.4360],\n",
      "         [-0.6680,  1.0187, -0.0526, -0.7445,  0.6723,  1.1974]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-1.6328, -2.4188,  0.0482, -0.1645,  0.2588, -0.6770],\n",
      "         [ 0.2660, -0.2154,  0.2836,  0.5583, -0.4973, -0.7654]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.0088, -0.7016,  0.6497,  0.2918,  1.5325,  0.3981],\n",
      "         [-1.3163, -0.3028,  1.1480,  1.4340,  0.3723, -0.1616]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.7325, -0.2853,  0.6958,  1.3609,  1.1616,  1.9086],\n",
      "         [-0.0327,  0.1406, -1.0349, -0.7295, -0.6333,  1.7291]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-1.1849,  1.2451, -0.1916,  1.2434,  1.3602, -0.8398],\n",
      "         [ 0.8563,  0.5200,  0.4137,  0.5259, -1.3513, -0.6591]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.2352,  0.1170,  0.7294, -1.4413,  0.9953,  0.5566],\n",
      "         [ 1.3722,  0.0433,  0.9180, -1.0709, -0.0882,  1.3723]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.1492,  1.1283,  0.8285, -0.5875,  1.2074, -0.9034],\n",
      "         [-0.5552, -1.9790,  0.5308, -0.3011,  1.1030, -0.5195]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-1.0060,  1.0087, -0.5674,  0.3871,  0.2948,  1.2069],\n",
      "         [-0.6081, -1.1027, -1.8158, -0.2526, -0.8456, -0.8509]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-2.6808,  0.7064,  2.2320,  1.1088, -0.1420,  0.3533],\n",
      "         [-0.5035,  0.3093, -0.7446,  1.1201, -0.1504,  0.8196]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.1567,  0.0086, -0.0639, -2.2316,  0.0079,  0.3021],\n",
      "         [ 1.0855,  1.1908, -0.5924, -1.4716,  1.2797,  0.6732]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 1.0799,  0.6067,  0.3031,  1.7998,  0.3456, -0.5633],\n",
      "         [-0.1261,  0.7779,  0.3668,  0.1018, -1.6119, -0.7713]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.0701, -1.5703, -0.9300, -2.0370,  1.4479,  1.3389],\n",
      "         [ 0.7028,  2.5971, -0.0565,  0.0342,  0.3209,  0.4871]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.6877,  0.4044, -0.4367,  1.7462, -1.5606,  0.8332],\n",
      "         [ 0.2403,  1.9067,  0.3975,  0.1661,  2.0239,  0.6018]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.0355,  0.6641, -1.3635,  0.3686, -0.4373,  0.4092],\n",
      "         [-2.5564, -0.4857, -1.2476, -1.0311,  2.1144, -0.3688]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.0508, -0.2597, -1.2479,  0.7286,  0.3809, -2.0653],\n",
      "         [-0.7283, -0.2648,  1.2677,  0.7181, -0.3197,  0.0072]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.7792,  0.2895,  0.4953,  0.8784, -0.1273,  1.2854],\n",
      "         [ 2.0531, -0.9473, -0.0319,  0.2977, -0.3574, -0.5426]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.5669,  1.6793,  3.4347,  0.4922, -0.9707,  0.0375],\n",
      "         [ 1.5247,  0.8883,  0.5113,  0.1436,  0.1822, -0.2749]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 1.9868, -0.3498, -0.4003, -1.0140, -0.4087, -1.4992],\n",
      "         [ 0.2609, -0.5276, -0.5644,  0.3093, -1.8441, -0.2796]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.7688,  1.0561,  0.5245,  2.3331, -1.1541, -0.3298],\n",
      "         [-0.6444,  0.6985, -1.1573, -0.7719, -0.0102,  0.3884]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.6321,  1.0005,  0.3751,  1.1064, -0.2894,  2.4706],\n",
      "         [-0.6771,  1.6432, -0.7909,  0.8168, -1.6363, -0.2423]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.8919,  0.9042, -0.3146, -0.3095, -1.0184,  0.8408],\n",
      "         [ 0.2003, -0.1013, -0.5826, -1.3282, -1.8616, -1.7130]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.9349,  1.1707, -0.5119,  0.2766, -0.3587, -0.8515],\n",
      "         [ 0.2911,  0.4152,  0.8757,  0.3320, -0.6432, -0.3133]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.5730,  0.5792,  2.1163,  1.0204,  0.3412, -1.5990],\n",
      "         [ 1.0179,  0.7285,  0.0554,  0.6396,  0.8354, -0.0980]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.8976, -1.3441, -0.5505, -0.9323, -0.4954,  2.0777],\n",
      "         [-0.4273,  0.2542,  1.1552,  1.0367, -0.7922, -1.8450]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 1.1518,  0.6655, -2.0930, -0.4815,  0.3600, -1.7550],\n",
      "         [ 0.5986,  2.1926, -0.5941, -2.1364, -0.9884, -0.8517]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-1.0012, -0.3524, -0.9288, -1.0771, -0.1135,  1.2869],\n",
      "         [-0.3099, -0.4632,  1.2465, -0.3109, -0.1712,  0.1897]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.5150, -0.5215, -1.1830, -1.9645, -0.4402, -0.9981],\n",
      "         [-0.5730, -0.6275, -0.9597, -2.3292, -0.1483, -0.5517]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.1042, -0.7330,  0.0625, -0.5274,  1.5171, -0.0809],\n",
      "         [ 0.1312,  0.3899, -1.1626, -0.9452,  0.7143,  0.1305]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.9838,  0.8161,  0.8541,  0.2340,  0.4542, -1.3755],\n",
      "         [-0.3788, -0.5165, -0.8277, -0.6963, -1.1559, -0.8306]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.1222,  0.1917,  0.6183, -0.5034,  0.7223,  0.8780],\n",
      "         [ 1.6329,  1.1873,  2.2275, -0.8509,  0.0876, -0.5051]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-1.2561,  0.4140, -1.0544, -0.2845,  1.5022, -0.7318],\n",
      "         [-0.4712,  0.0036, -0.5073, -0.2209,  0.4877,  0.7132]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.6790, -0.1613,  0.3293,  0.4955, -1.5935,  0.9860],\n",
      "         [ 0.9437, -0.1051,  1.3414,  0.8047, -1.0684, -1.9740]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.7692, -0.8875,  1.4865, -1.3362, -0.1464, -0.4290],\n",
      "         [-2.3897,  1.2029, -1.4347,  1.0680, -0.2261,  0.9221]]]) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.9263,  0.2312, -1.2219,  0.4115,  0.9288, -0.4923],\n",
      "         [-1.5197, -0.9824, -2.3778, -0.6846, -1.3168, -0.9545]]]) torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for x, y in dataloader:\n",
    "        h_0i = torch.randn(1, x.shape[0], 6)\n",
    "        print(h_0i, h_0i.shape)  # torch.Size([1, 2, 6])\n",
    "        pred = model(x, h_0i)\n",
    "        loss = loss_fn(pred, y)\n",
    "        ########\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "print(h_0i.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i say hello', 'he can sing'] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# ##test\n",
    "# input = [sen.split()[:2] for sen in sentences]\n",
    "# print(input)\n",
    "## 构建测试集\n",
    "input11 = list(['i say hello', 'he can sing'])\n",
    "print(input11, type(input11))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6])\n",
      "tensor([[[-0.8430,  0.5531,  0.2834, -1.0967,  1.4543, -0.0440],\n",
      "         [ 0.5925, -1.1021,  0.2076, -1.2035, -0.1570, -0.2859]]])\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.randn(1, 2, 6)\n",
    "\n",
    "print(hidden.shape)  # torch.Size([1, 2, 6])\n",
    "print(hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "[2, 8]\n",
      "tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]]) tensor([2, 8])\n"
     ]
    }
   ],
   "source": [
    "input_batch11, output_batch11 = make_data(input11)\n",
    "print(input_batch11, output_batch11)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3168, -1.4875,  1.2412, -0.9217, -1.6271, -1.3971, -0.6312, -1.6123,\n",
      "          0.1451, -1.0168,  0.1530,  0.6816, -1.4392],\n",
      "        [-1.2642, -1.2769,  0.7724, -1.0384, -1.3931, -1.1378, -0.5871, -1.1868,\n",
      "          0.8707, -0.9279, -0.3834,  0.1157, -1.3438]],\n",
      "       grad_fn=<AddmmBackward0>) torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# input_batch11=input_batch11.toTensor()\n",
    "\n",
    "predict = model(input_batch11, hidden)\n",
    "print(predict, predict.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [8]])\n"
     ]
    }
   ],
   "source": [
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'sing']\n"
     ]
    }
   ],
   "source": [
    "print([index2word[n.item()] for n in predict.squeeze()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}